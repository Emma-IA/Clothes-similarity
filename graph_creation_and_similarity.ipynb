{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jskaf/miniconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "#Load clustering models for tabular and image data\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load tabular data clustering model\n",
    "def load_tabular_model(model_path):\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "#Load image data clustering model\n",
    "def load_image_clustering_model(model_path):\n",
    "    model = torch.load(model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_img = 'models/image_clustering_model.pth'\n",
    "model_path_tab = 'models/kmeans_model.pkl'\n",
    "scaler_path = 'models/scaler.pkl'\n",
    "\n",
    "#Load image clustering model\n",
    "model_img = load_image_clustering_model(model_path_img)\n",
    "\n",
    "#Load tabular clustering model\n",
    "model_tab = load_tabular_model(model_path_tab)\n",
    "\n",
    "#Load scaler\n",
    "with open(scaler_path, 'rb') as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G_tab = nx.Graph()\n",
    "G_img = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/h&mdataset/articles.csv')\n",
    "df = df.drop(columns=['prod_name','product_code','product_type_no','department_no', 'index_code', \t\n",
    "       'product_type_name', 'product_group_name',\n",
    "       'graphical_appearance_name', 'colour_group_name', 'perceived_colour_value_name', 'perceived_colour_master_name', 'department_name', 'index_name', 'index_group_name', 'section_name', 'garment_group_name', 'detail_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df_scaled['cluster'] = model_tab.predict(df_scaled)\n",
    "\n",
    "#Add first the cluster nodes\n",
    "clusters = df_scaled['cluster'].unique()\n",
    "\n",
    "for cluster in tqdm(clusters):\n",
    "    G_tab.add_node(cluster, type='cluster')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the article nodes\n",
    "for i in tqdm(range(len(df_scaled))):\n",
    "    name_article = df_scaled['article_id'].iloc[i]\n",
    "    G_tab.add_node(f\"article {name_article}\", type='article', cluster=df_scaled['cluster'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the edges\n",
    "for i in tqdm(range(len(df_scaled))):\n",
    "    name_article = df_scaled['article_id'].iloc[i]\n",
    "    cluster = df_scaled['cluster'][i]\n",
    "    G_tab.add_edge(cluster, f\"article {name_article}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Using CUDA')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('Using MPS')\n",
    "else :\n",
    "    device = torch.device('cpu')\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import myDataset\n",
    "\n",
    "get_preprocessed_image = True\n",
    "batch_size = 64\n",
    "train_test_split = 0.9\n",
    "my_path_hm = os.path.join(os.getcwd(), 'data/h&mdataset/images/')\n",
    "my_path_fash = os.path.join(os.getcwd(), 'data/fashion-dataset/images/')\n",
    "\n",
    "dataset = myDataset(my_path_hm, my_path_fash, get_preprocessed_image, 'hm')\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to use a resnet50 from torchvision to have the embedding of an image, use a pretrained resnet and remove the last layer\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=True)\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        self.resnet.eval()\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add first the cluster nodes\n",
    "num_clusers = model_img.num_clusters\n",
    "\n",
    "for cluster in tqdm(range(num_clusers)):\n",
    "    G_img.add_node(cluster, type='cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe with as first column the image name and as second column the cluster assigned\n",
    "\n",
    "df_img = pd.DataFrame(columns=['image_name', 'cluster'])\n",
    "for i, batch in tqdm(enumerate(dataloader)):\n",
    "    embeddings = resnet_model(batch)\n",
    "    assignments = model_img(embeddings)\n",
    "    for j in range(len(assignments)):\n",
    "        df_img = df_img.append({'image_name': dataset.get_image_name(i*batch_size+j), 'cluster': assignments[j]}, ignore_index=True)\n",
    "\n",
    "#Save the dataframe\n",
    "df_img.to_csv('data/image_cluster.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the article nodes\n",
    "for i in tqdm(range(len(df_img))):\n",
    "    name_article = df_img['image_name'].iloc[i]\n",
    "    G_img.add_node(f\"article {name_article}\", type='article', cluster=df_img['cluster'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the edges\n",
    "for i in tqdm(range(len(df_img))):\n",
    "    name_article = df_img['image_name'].iloc[i]\n",
    "    cluster = df_img['cluster'][i]\n",
    "    G_img.add_edge(cluster, f\"article {name_article}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the graphs\n",
    "nx.write_gpickle(G_tab, 'data/tabular_graph.gpickle')\n",
    "nx.write_gpickle(G_img, 'data/image_graph.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the number of edges\n",
    "\n",
    "print(f\"Number of edges in the tabular graph: {G_tab.number_of_edges()}\")\n",
    "print(f\"Number of edges in the image graph: {G_img.number_of_edges()}\")\n",
    "print(f\"Number of nodes in the tabular graph: {G_tab.number_of_nodes()}\")\n",
    "print(f\"Number of nodes in the image graph: {G_img.number_of_nodes()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the two graphs using the Jaccard similarity\n",
    "\n",
    "def jaccard_similarity(g, h):\n",
    "    i = set(g).intersection(h)\n",
    "    return round(len(i) / (len(g) + len(h) - len(i)),3)\n",
    "\n",
    "jaccard_similarity(G_img.edges(), G_tab.edges())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
