{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load clustering models for tabular and image data\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import networkx as nx\n",
    "#use the sparce matrix to store the data\n",
    "from scipy.sparse import csr_matrix\n",
    "#Svd from scipy for sparse matrix\n",
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rechecker pour les indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load tabular data clustering model using joblib\n",
    "def load_tabular_model(model_path):\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "#Load image data clustering model\n",
    "def load_image_clustering_model(model_path):\n",
    "    model = torch.load(model_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_img = 'models/clustering_model_img.pth'\n",
    "model_path_tab = 'models/kmeans_model.pkl'\n",
    "scaler_path = 'models/scaler.pkl'\n",
    "\n",
    "#Load image clustering model\n",
    "model_img = load_image_clustering_model(model_path_img)\n",
    "\n",
    "#Load tabular clustering model\n",
    "model_tab = load_tabular_model(model_path_tab)\n",
    "\n",
    "#Load scaler\n",
    "with open(scaler_path, 'rb') as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_tab = nx.Graph()\n",
    "G_img = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/h&mdataset/articles.csv')\n",
    "df = df.drop(columns=['article_id','prod_name','product_code','product_type_no','department_no', 'index_code', \t\n",
    "       'product_type_name', 'product_group_name',\n",
    "       'graphical_appearance_name', 'colour_group_name', 'perceived_colour_value_name', 'perceived_colour_master_name', 'department_name', 'index_name', 'index_group_name', 'section_name', 'garment_group_name', 'detail_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import myDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "get_preprocessed_image = True\n",
    "batch_size = 64\n",
    "train_test_split = 0.9\n",
    "my_path_hm = os.path.join(os.getcwd(), 'data/h&mdataset/images/')\n",
    "my_path_fash = os.path.join(os.getcwd(), 'data/fashion-dataset/images/')\n",
    "\n",
    "dataset = myDataset(my_path_hm, my_path_fash, get_preprocessed_image, 'hm')\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df_scaled['cluster'] = model_tab.predict(df_scaled)\n",
    "\n",
    "#Add first the cluster nodes\n",
    "clusters = df_scaled['cluster'].unique()\n",
    "\n",
    "for cluster in tqdm(clusters):\n",
    "    G_tab.add_node(cluster, type='cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the article nodes\n",
    "for i in tqdm(range(len(df_scaled))):\n",
    "    name_article = dataset.get_name_img(i)\n",
    "    G_tab.add_node(i, type='article', cluster=df_scaled['cluster'][i], name=name_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the edges\n",
    "for i in tqdm(range(len(df_scaled))):\n",
    "    name_article = dataset.get_name_img(i)\n",
    "    cluster = df_scaled['cluster'].iloc[i]\n",
    "    G_tab.add_edge(cluster, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Using CUDA')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('Using MPS')\n",
    "else :\n",
    "    device = torch.device('cpu')\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to use a resnet50 from torchvision to have the embedding of an image, use a pretrained resnet and remove the last layer\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=True)\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        self.resnet.eval()\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = ResNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusteringModel(nn.Module):\n",
    "    def __init__(self, embedding_size, num_clusters):\n",
    "        super(ClusteringModel, self).__init__()\n",
    "        self.num_embeddings = embedding_size\n",
    "        self.num_clusters = num_clusters\n",
    "        self.centers = nn.Parameter(torch.randn(num_clusters, embedding_size))\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        embeddings = embeddings.flatten(2).flatten(1)\n",
    "        # Compute the distance between each embedding and each cluster center\n",
    "        distances = torch.cdist(embeddings, self.centers)\n",
    "        # Assign each embedding to the closest cluster\n",
    "        assignments = torch.argmin(distances, dim=1)\n",
    "        return assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 2048\n",
    "num_clusters = 200\n",
    "model_img = ClusteringModel(embedding_size, num_clusters).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add first the cluster nodes\n",
    "num_clusers = model_img.num_clusters\n",
    "\n",
    "for cluster in tqdm(range(num_clusers)):\n",
    "    G_img.add_node(cluster, type='cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe with as first column the image name and as second column the cluster assigned\n",
    "\n",
    "df_img = {'image_name': [], 'cluster': []}\n",
    "for batch in tqdm(dataloader):\n",
    "    imgs, idx, _ = batch\n",
    "    imgs = imgs.to(device)\n",
    "    embeddings = resnet_model(imgs)\n",
    "    assignments = model_img(embeddings)\n",
    "    for j in range(len(assignments)):\n",
    "        df_img['image_name'].append(dataset.get_name_img(idx[j]))\n",
    "        df_img['cluster'].append(assignments[j].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the dataframe\n",
    "df_img = pd.DataFrame(df_img)\n",
    "df_img.to_csv('data/image_cluster.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the article nodes\n",
    "for i in tqdm(range(len(df_img))):\n",
    "    name_article = df_img['image_name'].iloc[i]\n",
    "    G_img.add_node(i, type='article', cluster=df_img['cluster'][i], name=name_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the edges\n",
    "for i in tqdm(range(len(df_img))):\n",
    "    name_article = df_img['image_name'].iloc[i]\n",
    "    cluster = df_img['cluster'][i]\n",
    "    G_img.add_edge(cluster, f\"article {name_article}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the graphs\n",
    "nx.write_gexf(G_tab, \"models/graph_tab.gexf\")\n",
    "nx.write_gexf(G_img, \"models/graph_img.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the graphs\n",
    "G_tab = nx.read_gexf(\"models/graph_tab.gexf\")\n",
    "G_img = nx.read_gexf(\"models/graph_img.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the number of edges\n",
    "\n",
    "print(f\"Number of edges in the tabular graph: {G_tab.number_of_edges()}\")\n",
    "print(f\"Number of edges in the image graph: {G_img.number_of_edges()}\")\n",
    "print(f\"Number of nodes in the tabular graph: {G_tab.number_of_nodes()}\")\n",
    "print(f\"Number of nodes in the image graph: {G_img.number_of_nodes()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul_spectre_graphe(graph):\n",
    "    \"\"\"\n",
    "    Calcul du spectre d'un graphe\n",
    "    :param graph: un graphe\n",
    "    :return: le spectre\n",
    "    \"\"\"\n",
    "    #get the adjancy matrix as scipy sparse matrix\n",
    "    adj = nx.to_scipy_sparse_array(graph)\n",
    "    #transform the type of data into float\n",
    "    adj = adj.astype(float)\n",
    "    #get the eigenvalues\n",
    "    _, s, _ = svds(adj)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noyau_spectral(graph1, graph2, sigma):\n",
    "    \"\"\"\n",
    "    Noyau spectral entre deux graphes\n",
    "    :param graph1: le premier graphe\n",
    "    :param graph2: le deuxième graphe\n",
    "    :param sigma: l'hyperparamètre du noyau Gaussien (lien avec la variance)\n",
    "    :return: le produit scalaire entre les deux graphes\n",
    "    \"\"\"\n",
    "    s1 = calcul_spectre_graphe(graph1)\n",
    "    s2 = calcul_spectre_graphe(graph2)\n",
    "    diff = s1.shape[0] - s2.shape[0]\n",
    "    if diff < 0:\n",
    "        s1 = np.pad(s1, (0, -diff))\n",
    "    elif diff > 0:\n",
    "        s2 = np.pad(s2, (0, diff))\n",
    "    noyau = np.exp(-np.linalg.norm(s1 - s2) ** 2.0 / sigma ** 2.0)\n",
    "    return noyau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Noyau spectral du graphe tabulaire sur lui-même: {noyau_spectral(G_tab, G_tab, 1.0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Noyau spectral du graphe image sur lui-même: {noyau_spectral(G_img, G_img, 1.0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Noyau spectral entre les deux graphes: {noyau_spectral(G_tab, G_img, 1.0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage du graphe tabulaire\n",
    "import ipysigma \n",
    "ipysigma.Sigma(G_tab, node_color='cluster', edge_color='black')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
