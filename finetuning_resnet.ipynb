{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import myDataset_labelHM\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Using CUDA')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('Using MPS')\n",
    "else :\n",
    "    device = torch.device('cpu')\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x136105530>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fix random seed\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "path_csv = 'data/h&mdataset/articles.csv'\n",
    "path_images = 'data/h&mdataset/images/'\n",
    "batch_size = 64\n",
    "ratio_frozen_layers =  0.6\n",
    "num_epochs = 1\n",
    "learning_rate = 0.0001\n",
    "\n",
    "dataset = myDataset_labelHM(path_images, path_csv)\n",
    "num_classes = dataset.get_num_classes()\n",
    "\n",
    "#get a subset of the dataset\n",
    "subset_indices = torch.randperm(len(dataset))[:10000]\n",
    "num_samples_subset = len(subset_indices)\n",
    "\n",
    "train_size = int(0.8 * num_samples_subset)\n",
    "val_size = int(0.1 * num_samples_subset)\n",
    "test_size = num_samples_subset - train_size - val_size\n",
    "\n",
    "train_subset_indices = subset_indices[:train_size]\n",
    "val_subset_indices = subset_indices[train_size:train_size+val_size]\n",
    "test_subset_indices = subset_indices[train_size+val_size:]\n",
    "\n",
    "train_subset = torch.utils.data.Subset(dataset, train_subset_indices)\n",
    "val_subset = torch.utils.data.Subset(dataset, val_subset_indices)\n",
    "test_subset = torch.utils.data.Subset(dataset, test_subset_indices)\n",
    "\n",
    "#Save the indices in a file\n",
    "torch.save(train_subset_indices, 'data/h&mdataset/train_subset_indices.pt')\n",
    "torch.save(val_subset_indices, 'data/h&mdataset/val_subset_indices.pt')\n",
    "torch.save(test_subset_indices, 'data/h&mdataset/test_subset_indices.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train subset size: 8000\n"
     ]
    }
   ],
   "source": [
    "print('Train subset size:', len(train_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train/validation/test \n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=False)\n",
    "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=False)\n",
    "test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 81119,  70424,  60635,   1051,  81050,  23767,  47381, 101923,  88957,\n",
      "         94759,   6984,  26651, 102527,  11812,   2677,  67383,  10519,  46630,\n",
      "         28068,  66543,  48962,  60731,  86057, 101625,  84502,  76008,  22697,\n",
      "         11242,  79460,   4412,  14421,  24221,  85036,  87602,   2304, 104906,\n",
      "          7746,  33342,  18999,  61692,  63607,  15883,  84012,  21711,  82195,\n",
      "        101037,  81158,  74237,  79738,  69648,  89698,  49331,  41143,  52951,\n",
      "         17900,  34059,  83193,  20742,  42102,  70538,  42885,  56324,   7539,\n",
      "         16578])\n",
      "tensor([ 80403,  64076,  90293,  10383,    197,  39589,  77350, 103656,  19537,\n",
      "         48574,  45663,  94207,  93341,  57825, 103493,  65515,   1229,  85475,\n",
      "         61884,  26921,  41740, 102665,  22787,  57584,  11578,  17674,  31987,\n",
      "         56714,   1300,  45603,  10332,  17489,    327,  13100,   2469,  47585,\n",
      "         99257,  12221,   3737,  93298,  37414,  65238,  57441,  50673,   9499,\n",
      "          4081,  29255,  31408,  92846,  33965,  79717,  80473,  52808,   4354,\n",
      "          1223,   4421,  19882,  56220,  12098,  60586,  20231,  68153,  98573,\n",
      "         51830])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      2\u001b[0m     images, labels, idx, img_path \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(idx)\n",
      "File \u001b[0;32m~/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/torch/utils/data/dataset.py:399\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/torch/utils/data/dataset.py:399\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/Documents/Cours ECM 3A/CV/Clothes-similarity/dataset.py:144\u001b[0m, in \u001b[0;36mmyDataset_labelHM.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m : \n\u001b[1;32m    143\u001b[0m     img \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mPad(padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)(img)\n\u001b[0;32m--> 144\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in preprocessing image \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/torchvision/transforms/_presets.py:58\u001b[0m, in \u001b[0;36mImageClassification.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 58\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mantialias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     img \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcenter_crop(img, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrop_size)\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, Tensor):\n",
      "File \u001b[0;32m~/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/torchvision/transforms/functional.py:467\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    465\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    466\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m--> 467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39moutput_size, interpolation\u001b[38;5;241m=\u001b[39minterpolation\u001b[38;5;241m.\u001b[39mvalue, antialias\u001b[38;5;241m=\u001b[39mantialias)\n",
      "File \u001b[0;32m~/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/torchvision/transforms/_functional_pil.py:250\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot inappropriate size arg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/PIL/Image.py:2200\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2192\u001b[0m             \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2193\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2194\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2195\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2196\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2197\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2198\u001b[0m         )\n\u001b[0;32m-> 2200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    images, labels, idx, img_path = batch\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/jskaf/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 frozen layers out of 9 layers\n"
     ]
    }
   ],
   "source": [
    "#Finetuning of a pretrained model resnet50\n",
    "\n",
    "\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, num_classes, ratio_frozen_layers=0.0):\n",
    "        super(ResNet50, self).__init__()\n",
    "        self.ration_frozen_layers = ratio_frozen_layers\n",
    "        self.resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=True)\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        self.resnet.train()\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "        #get the layers of the resnet model\n",
    "        self.resnet_layers = list(self.resnet.children())\n",
    "        self.numbers_of_layers = len(self.resnet_layers)\n",
    "        self.numbers_of_frozen_layers = int(self.numbers_of_layers*self.ration_frozen_layers)\n",
    "        #freeze the layers of the resnet model to a certain layer defined by \"number of frozen layers\"\n",
    "        for i in range(0, self.numbers_of_frozen_layers):\n",
    "            for param in self.resnet_layers[i].parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def show_number_frozen_layers(self):\n",
    "        print(f'{self.numbers_of_frozen_layers} frozen layers out of {self.numbers_of_layers} layers')\n",
    "\n",
    "model = ResNet50(num_classes, ratio_frozen_layers)\n",
    "model.to(device)\n",
    "model.show_number_frozen_layers()\n",
    "\n",
    "#Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Fine tune all layers of the model except the last one for which we cant a higher learning rate\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model.resnet.parameters(), 'lr': learning_rate/100},\n",
    "    {'params': model.fc.parameters(), 'lr': learning_rate}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, epoch):\n",
    "    print('Training epoch {}'.format(epoch+1))\n",
    "    model.train()\n",
    "    training_loss = 0.0\n",
    "    index_batch = 0\n",
    "    for batch in train_loader:\n",
    "        images, labels ,_ ,_ = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        training_loss += loss.item()\n",
    "\n",
    "        \n",
    "        #Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        index_batch += 1\n",
    "        print('Batch {} out of {}'.format(index_batch, len(train_loader)), end='\\r')\n",
    "        # if index_batch%10 == 0:\n",
    "        #     print('Batch {} out of {}'.format(index_batch, len(train_loader)))\n",
    "    return training_loss/len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, epoch, criterion):\n",
    "    global num_classes\n",
    "    print('Evaluating epoch {}'.format(epoch+1))\n",
    "    model.eval()\n",
    "    validation_loss = 0.0\n",
    "    #Validation and print of accuracy per class\n",
    "    with torch.no_grad():\n",
    "        class_correct = list(0. for i in range(num_classes))\n",
    "        class_total = list(0. for i in range(num_classes))\n",
    "        index_batch = 0\n",
    "        for batch in val_loader:\n",
    "            images, labels, _ , _= batch\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            validation_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "            index_batch += 1\n",
    "            print('Batch {} out of {}'.format(index_batch, len(train_loader)), end='\\r')\n",
    "            # if index_batch%10 == 0:\n",
    "            #     print('Batch {} out of {}'.format(index_batch, len(val_loader)))\n",
    "\n",
    "        for i in range(num_classes):\n",
    "            if class_total[i] == 0:\n",
    "                print('No validation data for class {}'.format(i+1))\n",
    "            else:\n",
    "                print('Accuracy of class %5s : %2d %%' % (i+1, 100 * class_correct[i] / class_total[i]))\n",
    "    return validation_loss/len(val_loader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating epoch 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 16 out of 125\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:58<00:00, 118.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No validation data for class 1\n",
      "No validation data for class 2\n",
      "Accuracy of class     3 :  0 %\n",
      "Accuracy of class     4 :  0 %\n",
      "Accuracy of class     5 :  0 %\n",
      "Accuracy of class     6 :  0 %\n",
      "Accuracy of class     7 :  0 %\n",
      "No validation data for class 8\n",
      "Accuracy of class     9 :  0 %\n",
      "Accuracy of class    10 :  0 %\n",
      "Accuracy of class    11 :  0 %\n",
      "Accuracy of class    12 :  0 %\n",
      "No validation data for class 13\n",
      "Accuracy of class    14 :  0 %\n",
      "Accuracy of class    15 :  0 %\n",
      "Accuracy of class    16 :  0 %\n",
      "Accuracy of class    17 :  0 %\n",
      "Accuracy of class    18 :  0 %\n",
      "Accuracy of class    19 :  0 %\n",
      "Accuracy of class    20 :  0 %\n",
      "Accuracy of class    21 :  0 %\n",
      "Accuracy of class    22 :  0 %\n",
      "Accuracy of class    23 :  0 %\n",
      "Accuracy of class    24 :  0 %\n",
      "No validation data for class 25\n",
      "Accuracy of class    26 :  0 %\n",
      "Accuracy of class    27 :  0 %\n",
      "Accuracy of class    28 :  0 %\n",
      "Accuracy of class    29 :  0 %\n",
      "Accuracy of class    30 :  0 %\n",
      "Accuracy of class    31 :  0 %\n",
      "Accuracy of class    32 :  0 %\n",
      "Accuracy of class    33 :  0 %\n",
      "Accuracy of class    34 :  0 %\n",
      "Accuracy of class    35 :  0 %\n",
      "No validation data for class 36\n",
      "No validation data for class 37\n",
      "No validation data for class 38\n",
      "No validation data for class 39\n",
      "Accuracy of class    40 :  0 %\n",
      "Accuracy of class    41 :  0 %\n",
      "No validation data for class 42\n",
      "Accuracy of class    43 :  0 %\n",
      "No validation data for class 44\n",
      "No validation data for class 45\n",
      "Accuracy of class    46 :  0 %\n",
      "Accuracy of class    47 :  0 %\n",
      "Accuracy of class    48 : 10 %\n",
      "Accuracy of class    49 :  0 %\n",
      "Accuracy of class    50 :  0 %\n",
      "Accuracy of class    51 :  0 %\n",
      "Accuracy of class    52 :  0 %\n",
      "Accuracy of class    53 :  0 %\n",
      "Accuracy of class    54 :  0 %\n",
      "Accuracy of class    55 :  0 %\n",
      "No validation data for class 56\n",
      "Accuracy of class    57 :  0 %\n",
      "Accuracy of class    58 :  0 %\n",
      "Accuracy of class    59 :  0 %\n",
      "Accuracy of class    60 :  0 %\n",
      "Accuracy of class    61 : 37 %\n",
      "Accuracy of class    62 :  0 %\n",
      "Accuracy of class    63 :  0 %\n",
      "Accuracy of class    64 :  0 %\n",
      "No validation data for class 65\n",
      "Accuracy of class    66 : 52 %\n",
      "Accuracy of class    67 :  0 %\n",
      "Accuracy of class    68 :  0 %\n",
      "Accuracy of class    69 :  0 %\n",
      "No validation data for class 70\n",
      "Accuracy of class    71 :  0 %\n",
      "No validation data for class 72\n",
      "No validation data for class 73\n",
      "No validation data for class 74\n",
      "Accuracy of class    75 :  0 %\n",
      "Accuracy of class    76 :  0 %\n",
      "No validation data for class 77\n",
      "No validation data for class 78\n",
      "No validation data for class 79\n",
      "Accuracy of class    80 :  0 %\n",
      "Accuracy of class    81 :  0 %\n",
      "No validation data for class 82\n",
      "Accuracy of class    83 :  0 %\n",
      "Accuracy of class    84 :  0 %\n",
      "Accuracy of class    85 :  0 %\n",
      "No validation data for class 86\n",
      "Accuracy of class    87 :  0 %\n",
      "No validation data for class 88\n",
      "Accuracy of class    89 :  0 %\n",
      "Accuracy of class    90 :  0 %\n",
      "Accuracy of class    91 :  0 %\n",
      "No validation data for class 92\n",
      "Accuracy of class    93 :  0 %\n",
      "No validation data for class 94\n",
      "No validation data for class 95\n",
      "No validation data for class 96\n",
      "No validation data for class 97\n",
      "No validation data for class 98\n",
      "No validation data for class 99\n",
      "No validation data for class 100\n",
      "No validation data for class 101\n",
      "No validation data for class 102\n",
      "No validation data for class 103\n",
      "No validation data for class 104\n",
      "No validation data for class 105\n",
      "No validation data for class 106\n",
      "No validation data for class 107\n",
      "No validation data for class 108\n",
      "No validation data for class 109\n",
      "No validation data for class 110\n",
      "No validation data for class 111\n",
      "No validation data for class 112\n",
      "No validation data for class 113\n",
      "Accuracy of class   114 :  0 %\n",
      "No validation data for class 115\n",
      "No validation data for class 116\n",
      "No validation data for class 117\n",
      "Accuracy of class   118 :  0 %\n",
      "No validation data for class 119\n",
      "Accuracy of class   120 :  0 %\n",
      "No validation data for class 121\n",
      "No validation data for class 122\n",
      "No validation data for class 123\n",
      "No validation data for class 124\n",
      "No validation data for class 125\n",
      "No validation data for class 126\n",
      "No validation data for class 127\n",
      "No validation data for class 128\n",
      "No validation data for class 129\n",
      "No validation data for class 130\n",
      "No validation data for class 131\n",
      "No validation data for class 132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    train_loss = train(model, train_loader, criterion, optimizer, epoch)\n",
    "    validation_loss = evaluate(model, val_loader, epoch, criterion)\n",
    "    train_losses.append(train_loss)\n",
    "    validation_losses.append(validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "torch.save(model.state_dict(), 'models/resnet_finetuned.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7k0lEQVR4nO3de3gU5f3//9cmJEsg7AZQcuYgBAyRgA2HLnh5qEGgCsFaD3zQoEUpEARPNOanyEEhaJCCYgNVFNRiLNFYFDCKHFROgoKNIiAVCEpCrJgsRHNwd35/8GXrmgNZksAkPh/XNRfszHtm7nvYy305c8+MxTAMQwAAACbmd74bAAAAcCYEFgAAYHoEFgAAYHoEFgAAYHoEFgAAYHoEFgAAYHoEFgAAYHoEFgAAYHotzncDGorb7dbRo0fVpk0bWSyW890cAABQB4Zh6MSJE4qIiJCfX83nUZpNYDl69Kiio6PPdzMAAMBZOHLkiKKiompc3mwCS5s2bSSd6rDNZjvPrQEAAHXhdDoVHR3t+R2vSbMJLKcvA9lsNgILAABNzJmGczDoFgAAmB6BBQAAmB6BBQAAmF6zGcMCAGg4hmHop59+ksvlOt9NQRPn7++vFi1a1PuRIwQWAICXiooKFRQU6IcffjjfTUEz0apVK4WHhyswMPCst0FgAQB4uN1uHTx4UP7+/oqIiFBgYCAP48RZMwxDFRUV+vbbb3Xw4EHFxMTU+nC42hBYAAAeFRUVcrvdio6OVqtWrc53c9AMBAUFKSAgQIcPH1ZFRYVatmx5Vtth0C0AoIqz/b9goDoN8X3iGwkAAEyPwAIAAEyPwAIAQDU6d+6sBQsW1Ll+48aNslgsKi4ubrQ2SdKyZcsUEhLSqPswIwILAKBJs1gstU4zZsw4q+3u2LFD48aNq3P9wIEDVVBQILvdflb7Q+24SwgA0KQVFBR4/v7qq6/qkUce0b59+zzzgoODPX83DEMul0stWpz55+/CCy/0qR2BgYEKCwvzaR3UHWdYAAA1MgxDP1T8dF4mwzDq1MawsDDPZLfbZbFYPJ/37t2rNm3aaO3atUpISJDVatWHH36o//znP0pKSlJoaKiCg4PVr18/rVu3zmu7v7wkZLFY9Nxzz+n6669Xq1atFBMTo1WrVnmW//KS0OlLN7m5uYqNjVVwcLCGDh3qFbB++uknTZ48WSEhIWrfvr1SU1M1ZswYjRw50qd/p8zMTHXt2lWBgYHq0aOHXnrpJa9/wxkzZqhjx46yWq2KiIjQ5MmTPcv/9re/KSYmRi1btlRoaKj++Mc/+rTvc4UzLACAGv1Y6VLPR3LPy773zBqiVoEN8zP14IMPat68ebrooovUtm1bHTlyRL///e81e/ZsWa1Wvfjiixo+fLj27dunjh071ridmTNn6oknnlBGRoaefvppjR49WocPH1a7du2qrf/hhx80b948vfTSS/Lz89Ott96qBx54QP/4xz8kSY8//rj+8Y9/6IUXXlBsbKwWLlyoN954Q1dddVWd+5aTk6MpU6ZowYIFSkxM1FtvvaU77rhDUVFRuuqqq/Taa6/pr3/9q7KyshQXF6fCwkJ9+umnkqSdO3dq8uTJeumllzRw4EAdP35cH3zwgQ9H9twhsAAAmr1Zs2Zp8ODBns/t2rVT7969PZ8fffRR5eTkaNWqVZo0aVKN27n99ts1atQoSdKcOXP01FNP6aOPPtLQoUOrra+srNTixYvVtWtXSdKkSZM0a9Ysz/Knn35aaWlpuv766yVJixYt0po1a3zq27x583T77bdr4sSJkqT77rtP27Zt07x583TVVVcpPz9fYWFhSkxMVEBAgDp27Kj+/ftLkvLz89W6dWtdd911atOmjTp16qRLL73Up/2fKwQWAECNggL8tWfWkPO274bSt29fr88nT57UjBkztHr1ahUUFOinn37Sjz/+qPz8/Fq3Ex8f7/l769atZbPZVFRUVGN9q1atPGFFksLDwz31JSUlOnbsmCc8SKdeFJiQkCC3213nvn3xxRdVBgcPGjRICxculCTdeOONWrBggS666CINHTpUv//97zV8+HC1aNFCgwcPVqdOnTzLhg4d6rnkZTaMYQEA1MhisahVYIvzMjXkO4xat27t9fmBBx5QTk6O5syZow8++EC7d+9Wr169VFFRUet2AgICqhyf2sJFdfV1HZvTUKKjo7Vv3z797W9/U1BQkCZOnKjLL79clZWVatOmjT755BO98sorCg8P1yOPPKLevXs3+q3ZZ8OnwJKZman4+HjZbDbZbDY5HA6tXbu2xvorr7yy2lvMrr32WkmnTpWlpqaqV69eat26tSIiIpScnKyjR4/Wr1cAANRi8+bNuv3223X99derV69eCgsL06FDh85pG+x2u0JDQ7Vjxw7PPJfLpU8++cSn7cTGxmrz5s1e8zZv3qyePXt6PgcFBWn48OF66qmntHHjRm3dulV5eXmSpBYtWigxMVFPPPGE/v3vf+vQoUNav359PXrWOHy6JBQVFaW5c+cqJiZGhmFo+fLlSkpK0q5duxQXF1el/vXXX/dKq99995169+6tG2+8UdKpwUiffPKJpk2bpt69e+v777/XlClTNGLECO3cubOeXQMAoHoxMTF6/fXXNXz4cFksFk2bNs2nyzAN5e6771Z6erq6deumiy++WE8//bS+//57n84uTZ06VTfddJMuvfRSJSYm6s0339Trr7/uuetp2bJlcrlcGjBggFq1aqWXX35ZQUFB6tSpk9566y199dVXuvzyy9W2bVutWbNGbrdbPXr0aKwunzWfAsvw4cO9Ps+ePVuZmZnatm1btYHll6Oms7Ky1KpVK09gsdvtevfdd71qFi1apP79+ys/P7/WkdoAAJyt+fPn609/+pMGDhyoCy64QKmpqXI6nee8HampqSosLFRycrL8/f01btw4DRkyRP7+dR+/M3LkSC1cuFDz5s3TlClT1KVLF73wwgu68sorJUkhISGaO3eu7rvvPrlcLvXq1Utvvvmm2rdvr5CQEL3++uuaMWOGysrKFBMTo1deeaXa3/TzzWKc5cU0l8ullStXasyYMdq1a5fXqaea9OrVSw6HQ3//+99rrFm3bp2uueYaFRcXy2az1bk9TqdTdrtdJSUlPq0HAPifsrIyHTx4UF26dFHLli3Pd3N+ddxut2JjY3XTTTfp0UcfPd/NaTC1fa/q+vvt811CeXl5cjgcKisrU3BwsHJycuoUVj766CN99tlnWrp0aY01ZWVlSk1N1ahRo84YOsrLy1VeXu75fD6SMQAA9XH48GG98847uuKKK1ReXq5Fixbp4MGD+r//+7/z3TTT8fkuoR49emj37t3avn27JkyYoDFjxmjPnj1nXG/p0qXq1auX1+1bP1dZWambbrpJhmEoMzPzjNtLT0+X3W73TNHR0b52BQCA88rPz0/Lli1Tv379NGjQIOXl5WndunWKjY09300znbO+JHRaYmKiunbtqiVLltRYU1paqoiICM2aNUtTpkypsvx0WPnqq6+0fv16tW/f/oz7re4MS3R0NJeEAKAeuCSExnBeLgn9ktvt9goO1Vm5cqXKy8t16623Vll2Oqx8+eWX2rBhQ53CiiRZrVZZrdazajMAAGhafAosaWlpGjZsmDp27KgTJ05oxYoV2rhxo3JzT71nIjk5WZGRkUpPT/dab+nSpRo5cmSVMFJZWak//vGP+uSTT/TWW2/J5XKpsLBQ0qk7jAIDA+vTNwAA0Ez4FFiKioqUnJysgoIC2e12xcfHKzc31/N+hvz8fPn5eQ+L2bdvnz788EO98847Vbb3zTffeN502adPH69lGzZs8NySBQAAft18Ciy13eEjnXq19i/16NGjxscQd+7c+Zw/ohgAADQ9vEsIAACYHoEFAACdev/dPffc4/ncuXNnLViwoNZ1LBaL3njjjXrvu6G2U5sZM2ZUGX7RlBBYAABN2vDhwzV06NBql33wwQeyWCz697//7fN2d+zYoXHjxtW3eV5qCg0FBQUaNmxYg+6ruSGwAACatLFjx+rdd9/V119/XWXZCy+8oL59+yo+Pt7n7V544YVq1apVQzTxjMLCwnhUxxkQWAAATdp1112nCy+8UMuWLfOaf/LkSa1cuVJjx47Vd999p1GjRikyMlKtWrVSr1699Morr9S63V9eEvryyy91+eWXq2XLlurZs2eVl/dKp15m2L17d7Vq1UoXXXSRpk2bpsrKSkmn3po8c+ZMffrpp7JYLLJYLJ42//KSUF5enn73u98pKChI7du317hx43Ty5EnP8ttvv10jR47UvHnzFB4ervbt2yslJcWzr7pwu92aNWuWoqKiZLVa1adPH7399tue5RUVFZo0aZLCw8PVsmVLderUyfPYEsMwNGPGDHXs2FFWq1URERGaPHlynfd9Nur94DgAQDNmGFLlD+dn3wGtJIvljGUtWrRQcnKyli1bpoceekiW/7fOypUr5XK5NGrUKJ08eVIJCQlKTU2VzWbT6tWrddttt6lr1641vjLm59xut/7whz8oNDRU27dvV0lJidd4l9PatGmjZcuWKSIiQnl5ebrrrrvUpk0b/eUvf9HNN9+szz77TG+//bbWrVsnSbLb7VW2UVpaqiFDhsjhcGjHjh0qKirSnXfeqUmTJnmFsg0bNig8PFwbNmzQgQMHdPPNN6tPnz666667ztgfSVq4cKGefPJJLVmyRJdeeqmef/55jRgxQp9//rliYmL01FNPadWqVfrnP/+pjh076siRIzpy5Igk6bXXXtNf//pXZWVlKS4uToWFhfr000/rtN+zRWABANSs8gdpTsT52ff/d1QKbF2n0j/96U/KyMjQpk2bPM/weuGFF3TDDTd43jn3wAMPeOrvvvtu5ebm6p///GedAsu6deu0d+9e5ebmKiLi1PGYM2dOlXEnDz/8sOfvnTt31gMPPKCsrCz95S9/UVBQkIKDg9WiRQuFhYXVuK8VK1aorKxML774olq3PtX/RYsWafjw4Xr88ccVGhoqSWrbtq0WLVokf39/XXzxxbr22mv13nvv1TmwzJs3T6mpqbrlllskSY8//rg2bNigBQsW6JlnnlF+fr5iYmJ02WWXyWKxqFOnTp518/PzFRYWpsTERAUEBKhjx451Oo71wSUhAECTd/HFF2vgwIF6/vnnJUkHDhzQBx98oLFjx0qSXC6XHn30UfXq1Uvt2rVTcHCwcnNzlZ+fX6ftf/HFF4qOjvaEFUlyOBxV6l599VUNGjRIYWFhCg4O1sMPP1znffx8X7179/aEFUkaNGiQ3G639u3b55kXFxcnf39/z+fw8HAVFRXVaR9Op1NHjx7VoEGDvOYPGjRIX3zxhaRTl512796tHj16aPLkyV4PgL3xxhv1448/6qKLLtJdd92lnJwc/fTTTz7101ecYQEA1Cyg1akzHedr3z4YO3as7r77bj3zzDN64YUX1LVrV11xxRWSpIyMDC1cuFALFixQr1691Lp1a91zzz2qqKhosOZu3bpVo0eP1syZMzVkyBDZ7XZlZWXpySefbLB9/FxAQIDXZ4vFIrfb3WDb/81vfqODBw9q7dq1WrdunW666SYlJiYqOztb0dHR2rdvn9atW6d3331XEydO9Jzh+mW7GgpnWAAANbNYTl2WOR9THcav/NxNN90kPz8/rVixQi+++KL+9Kc/ecazbN68WUlJSbr11lvVu3dvXXTRRdq/f3+dtx0bG6sjR46ooKDAM2/btm1eNVu2bFGnTp300EMPqW/fvoqJidHhw4e9agIDA+Vyuc64r08//VSlpaWeeZs3b5afn5969OhR5zbXxmazKSIiQps3b/aav3nzZvXs2dOr7uabb9azzz6rV199Va+99pqOHz8uSQoKCtLw4cP11FNPaePGjdq6davy8vIapH3V4QwLAKBZCA4O1s0336y0tDQ5nU7dfvvtnmUxMTHKzs7Wli1b1LZtW82fP1/Hjh3z+nGuTWJiorp3764xY8YoIyNDTqdTDz30kFdNTEyM8vPzlZWVpX79+mn16tXKycnxquncubMOHjyo3bt3KyoqSm3atKlyO/Po0aM1ffp0jRkzRjNmzNC3336ru+++W7fddptn/EpDmDp1qqZPn66uXbuqT58+euGFF7R792794x//kCTNnz9f4eHhuvTSS+Xn56eVK1cqLCxMISEhWrZsmVwulwYMGKBWrVrp5ZdfVlBQkNc4l4bGGRYAQLMxduxYff/99xoyZIjXeJOHH35Yv/nNbzRkyBBdeeWVCgsL08iRI+u8XT8/P+Xk5OjHH39U//79deedd2r27NleNSNGjNC9996rSZMmqU+fPtqyZYumTZvmVXPDDTdo6NChuuqqq3ThhRdWe2t1q1atlJubq+PHj6tfv3764x//qKuvvlqLFi3y7WCcweTJk3Xffffp/vvvV69evfT2229r1apViomJkXTqjqcnnnhCffv2Vb9+/XTo0CGtWbNGfn5+CgkJ0bPPPqtBgwYpPj5e69at05tvvqn27ds3aBt/zmI0k7cPOp1O2e12lZSUyGazne/mAECTVFZWpoMHD6pLly5q2bLl+W4Omonavld1/f3mDAsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAoIpmcgMpTKIhvk8EFgCAx+nHqv/ww3l6QzOapdPfp/o8tp8n3QIAPPz9/RUSEuJ5iV6rVq08j7cHfGUYhn744QcVFRUpJCTE62WNviKwAAC8hIWFSVKd3/wLnElISIjne3W2CCwAAC8Wi0Xh4eHq0KGDKisrz3dz0MQFBATU68zKaQQWAEC1/P39G+SHBmgIDLoFAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACmR2ABAACm51NgyczMVHx8vGw2m2w2mxwOh9auXVtj/ZVXXimLxVJluvbaaz01hmHokUceUXh4uIKCgpSYmKgvv/zy7HsEAACaHZ8CS1RUlObOnauPP/5YO3fu1O9+9zslJSXp888/r7b+9ddfV0FBgWf67LPP5O/vrxtvvNFT88QTT+ipp57S4sWLtX37drVu3VpDhgxRWVlZ/XoGAACaDYtRz3c+t2vXThkZGRo7duwZaxcsWKBHHnlEBQUFat26tQzDUEREhO6//3498MADkqSSkhKFhoZq2bJluuWWW+rcDqfTKbvdrpKSEtlstrPuDwAAOHfq+vt91mNYXC6XsrKyVFpaKofDUad1li5dqltuuUWtW7eWJB08eFCFhYVKTEz01Njtdg0YMEBbt26tdVvl5eVyOp1eEwAAaJ58Dix5eXkKDg6W1WrV+PHjlZOTo549e55xvY8++kifffaZ7rzzTs+8wsJCSVJoaKhXbWhoqGdZTdLT02W32z1TdHS0r10BAABNhM+BpUePHtq9e7e2b9+uCRMmaMyYMdqzZ88Z11u6dKl69eql/v37n1VDfyktLU0lJSWe6ciRIw2yXQAAYD4+B5bAwEB169ZNCQkJSk9PV+/evbVw4cJa1yktLVVWVlaVcS5hYWGSpGPHjnnNP3bsmGdZTaxWq+dupdMTAABonur9HBa3263y8vJaa1auXKny8nLdeuutXvO7dOmisLAwvffee555TqdT27dvr/O4GAAA0Py18KU4LS1Nw4YNU8eOHXXixAmtWLFCGzduVG5uriQpOTlZkZGRSk9P91pv6dKlGjlypNq3b+8132Kx6J577tFjjz2mmJgYdenSRdOmTVNERIRGjhxZv54BAIBmw6fAUlRUpOTkZBUUFMhutys+Pl65ubkaPHiwJCk/P19+ft4nbfbt26cPP/xQ77zzTrXb/Mtf/qLS0lKNGzdOxcXFuuyyy/T222+rZcuWZ9klAADQ3NT7OSxmwXNYAABoehr9OSwAAADnCoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYHoEFAACYnk+BJTMzU/Hx8bLZbLLZbHI4HFq7dm2t6xQXFyslJUXh4eGyWq3q3r271qxZ41nucrk0bdo0denSRUFBQerataseffRRGYZxdj0CAADNTgtfiqOiojR37lzFxMTIMAwtX75cSUlJ2rVrl+Li4qrUV1RUaPDgwerQoYOys7MVGRmpw4cPKyQkxFPz+OOPKzMzU8uXL1dcXJx27typO+64Q3a7XZMnT653BwEAQNNnMep5KqNdu3bKyMjQ2LFjqyxbvHixMjIytHfvXgUEBFS7/nXXXafQ0FAtXbrUM++GG25QUFCQXn755Tq3w+l0ym63q6SkRDabzfeOAACAc66uv99nPYbF5XIpKytLpaWlcjgc1dasWrVKDodDKSkpCg0N1SWXXKI5c+bI5XJ5agYOHKj33ntP+/fvlyR9+umn+vDDDzVs2LBa919eXi6n0+k1AQCA5smnS0KSlJeXJ4fDobKyMgUHBysnJ0c9e/astvarr77S+vXrNXr0aK1Zs0YHDhzQxIkTVVlZqenTp0uSHnzwQTmdTl188cXy9/eXy+XS7NmzNXr06FrbkZ6erpkzZ/rafAAA0AT5fEmooqJC+fn5KikpUXZ2tp577jlt2rSp2tDSvXt3lZWV6eDBg/L395ckzZ8/XxkZGSooKJAkZWVlaerUqcrIyFBcXJx2796te+65R/Pnz9eYMWNqbEd5ebnKy8s9n51Op6Kjo7kkBABAE1LXS0I+n2EJDAxUt27dJEkJCQnasWOHFi5cqCVLllSpDQ8PV0BAgCesSFJsbKwKCwtVUVGhwMBATZ06VQ8++KBuueUWSVKvXr10+PBhpaen1xpYrFarrFarr80HAABNUL2fw+J2u73OdPzcoEGDdODAAbndbs+8/fv3Kzw8XIGBgZKkH374QX5+3s3w9/f3WgcAAPy6+RRY0tLS9P777+vQoUPKy8tTWlqaNm7c6BlvkpycrLS0NE/9hAkTdPz4cU2ZMkX79+/X6tWrNWfOHKWkpHhqhg8frtmzZ2v16tU6dOiQcnJyNH/+fF1//fUN1EUAANDU+XRJqKioSMnJySooKJDdbld8fLxyc3M1ePBgSVJ+fr7X2ZLo6Gjl5ubq3nvvVXx8vCIjIzVlyhSlpqZ6ap5++mlNmzZNEydOVFFRkSIiIvTnP/9ZjzzySAN1EQAANHX1fg6LWfAcFgAAmp5Gfw4LAADAuUJgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApkdgAQAApudTYMnMzFR8fLxsNptsNpscDofWrl1b6zrFxcVKSUlReHi4rFarunfvrjVr1njVfPPNN7r11lvVvn17BQUFqVevXtq5c6fvvQEAAM1SC1+Ko6KiNHfuXMXExMgwDC1fvlxJSUnatWuX4uLiqtRXVFRo8ODB6tChg7KzsxUZGanDhw8rJCTEU/P9999r0KBBuuqqq7R27VpdeOGF+vLLL9W2bdt6dw4AADQPFsMwjPpsoF27dsrIyNDYsWOrLFu8eLEyMjK0d+9eBQQEVLv+gw8+qM2bN+uDDz6oTzPkdDplt9tVUlIim81Wr20BAIBzo66/32c9hsXlcikrK0ulpaVyOBzV1qxatUoOh0MpKSkKDQ3VJZdcojlz5sjlcnnV9O3bVzfeeKM6dOigSy+9VM8+++wZ919eXi6n0+k1AQCA5snnwJKXl6fg4GBZrVaNHz9eOTk56tmzZ7W1X331lbKzs+VyubRmzRpNmzZNTz75pB577DGvmszMTMXExCg3N1cTJkzQ5MmTtXz58lrbkZ6eLrvd7pmio6N97QoAAGgifL4kVFFRofz8fJWUlCg7O1vPPfecNm3aVG1o6d69u8rKynTw4EH5+/tLkubPn6+MjAwVFBRIkgIDA9W3b19t2bLFs97kyZO1Y8cObd26tcZ2lJeXq7y83PPZ6XQqOjqaS0IAADQhdb0k5NOgW+lUwOjWrZskKSEhQTt27NDChQu1ZMmSKrXh4eEKCAjwhBVJio2NVWFhoSoqKhQYGKjw8PAqYSc2NlavvfZare2wWq2yWq2+Nh8AADRB9X4Oi9vt9jrT8XODBg3SgQMH5Ha7PfP279+v8PBwBQYGemr27dvntd7+/fvVqVOn+jYNAAA0Ez4FlrS0NL3//vs6dOiQ8vLylJaWpo0bN2r06NGSpOTkZKWlpXnqJ0yYoOPHj2vKlCnav3+/Vq9erTlz5iglJcVTc++992rbtm2aM2eODhw4oBUrVujvf/+7Vw0AAPh18+mSUFFRkZKTk1VQUCC73a74+Hjl5uZq8ODBkqT8/Hz5+f0vA0VHRys3N1f33nuv4uPjFRkZqSlTpig1NdVT069fP+Xk5CgtLU2zZs1Sly5dtGDBAk8IAgAAqPdzWMyC57AAAND0NPpzWAAAAM4VAgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9nwJLZmam4uPjZbPZZLPZ5HA4tHbt2lrXKS4uVkpKisLDw2W1WtW9e3etWbOm2tq5c+fKYrHonnvu8aVZAACgmWvhS3FUVJTmzp2rmJgYGYah5cuXKykpSbt27VJcXFyV+oqKCg0ePFgdOnRQdna2IiMjdfjwYYWEhFSp3bFjh5YsWaL4+Piz7gwAAGiefAosw4cP9/o8e/ZsZWZmatu2bdUGlueff17Hjx/Xli1bFBAQIEnq3LlzlbqTJ09q9OjRevbZZ/XYY4/50iQAAPArcNZjWFwul7KyslRaWiqHw1FtzapVq+RwOJSSkqLQ0FBdcsklmjNnjlwul1ddSkqKrr32WiUmJtZ5/+Xl5XI6nV4TAABonnw6wyJJeXl5cjgcKisrU3BwsHJyctSzZ89qa7/66iutX79eo0eP1po1a3TgwAFNnDhRlZWVmj59uiQpKytLn3zyiXbs2OFTO9LT0zVz5kxfmw8AAJogi2EYhi8rVFRUKD8/XyUlJcrOztZzzz2nTZs2VRtaunfvrrKyMh08eFD+/v6SpPnz5ysjI0MFBQU6cuSI+vbtq3fffdczduXKK69Unz59tGDBglrbUV5ervLycs9np9Op6OholZSUyGaz+dIlAABwnjidTtnt9jP+fvt8hiUwMFDdunWTJCUkJGjHjh1auHChlixZUqU2PDxcAQEBnrAiSbGxsSosLFRFRYU+/vhjFRUV6Te/+Y1nucvl0vvvv69FixapvLzca92fs1qtslqtvjYfAAA0QT4Hll9yu91eZzp+btCgQVqxYoXcbrf8/E4Nl9m/f7/Cw8MVGBioq6++Wnl5eV7r3HHHHbr44ouVmppaY1gBAAC/Lj4FlrS0NA0bNkwdO3bUiRMntGLFCm3cuFG5ubmSpOTkZEVGRio9PV2SNGHCBC1atEhTpkzR3XffrS+//FJz5szR5MmTJUlt2rTRJZdc4rWP1q1bq3379lXmAwCAXy+fAktRUZGSk5NVUFAgu92u+Ph45ebmavDgwZKk/Px8z5kUSYqOjlZubq7uvfdexcfHKzIyUlOmTFFqamrD9gIAADRrPg+6Nau6DtoBAADmUdffb94lBAAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATI/AAgAATM+nwJKZman4+HjZbDbZbDY5HA6tXbu21nWKi4uVkpKi8PBwWa1Wde/eXWvWrPEsT09PV79+/dSmTRt16NBBI0eO1L59+86uNwAAoFnyKbBERUVp7ty5+vjjj7Vz50797ne/U1JSkj7//PNq6ysqKjR48GAdOnRI2dnZ2rdvn5599llFRkZ6ajZt2qSUlBRt27ZN7777riorK3XNNdeotLS0fj0DAADNhsUwDKM+G2jXrp0yMjI0duzYKssWL16sjIwM7d27VwEBAXXa3rfffqsOHTpo06ZNuvzyy+vcDqfTKbvdrpKSEtlstjqvBwAAzp+6/n6f9RgWl8ulrKwslZaWyuFwVFuzatUqORwOpaSkKDQ0VJdcconmzJkjl8tV43ZLSkoknQpCtSkvL5fT6fSaAABA89TC1xXy8vLkcDhUVlam4OBg5eTkqGfPntXWfvXVV1q/fr1Gjx6tNWvW6MCBA5o4caIqKys1ffr0KvVut1v33HOPBg0apEsuuaTWdqSnp2vmzJm+Nh8AADRBPl8SqqioUH5+vkpKSpSdna3nnntOmzZtqja0dO/eXWVlZTp48KD8/f0lSfPnz1dGRoYKCgqq1E+YMEFr167Vhx9+qKioqFrbUV5ervLycs9np9Op6OhoLgkBANCE1PWSkM9nWAIDA9WtWzdJUkJCgnbs2KGFCxdqyZIlVWrDw8MVEBDgCSuSFBsbq8LCQlVUVCgwMNAzf9KkSXrrrbf0/vvvnzGsSJLVapXVavW1+QAAoAmq93NY3G6315mOnxs0aJAOHDggt9vtmbd//36Fh4d7wophGJo0aZJycnK0fv16denSpb5NAgAAzYxPgSUtLU3vv/++Dh06pLy8PKWlpWnjxo0aPXq0JCk5OVlpaWme+gkTJuj48eOaMmWK9u/fr9WrV2vOnDlKSUnx1KSkpOjll1/WihUr1KZNGxUWFqqwsFA//vhjA3URAAA0dT5dEioqKlJycrIKCgpkt9sVHx+v3NxcDR48WJKUn58vP7//ZaDo6Gjl5ubq3nvvVXx8vCIjIzVlyhSlpqZ6ajIzMyVJV155pde+XnjhBd1+++1n2S0AANCc1Ps5LGbBc1gAAGh6Gv05LAAAAOcKgQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJgegQUAAJieT4ElMzNT8fHxstlsstlscjgcWrt2ba3rFBcXKyUlReHh4bJarerevbvWrFnjVfPMM8+oc+fOatmypQYMGKCPPvrI954AAIBmq4UvxVFRUZo7d65iYmJkGIaWL1+upKQk7dq1S3FxcVXqKyoqNHjwYHXo0EHZ2dmKjIzU4cOHFRIS4ql59dVXdd9992nx4sUaMGCAFixYoCFDhmjfvn3q0KFDvTsIAACaPothGEZ9NtCuXTtlZGRo7NixVZYtXrxYGRkZ2rt3rwICAqpdf8CAAerXr58WLVokSXK73YqOjtbdd9+tBx98sM7tcDqdstvtKikpkc1mO7vOAACAc6quv99nPYbF5XIpKytLpaWlcjgc1dasWrVKDodDKSkpCg0N1SWXXKI5c+bI5XJJOnUG5uOPP1ZiYuL/GuTnp8TERG3durXW/ZeXl8vpdHpNAACgefI5sOTl5Sk4OFhWq1Xjx49XTk6OevbsWW3tV199pezsbLlcLq1Zs0bTpk3Tk08+qccee0yS9N///lcul0uhoaFe64WGhqqwsLDWdqSnp8tut3um6OhoX7sCAACaCJ8DS48ePbR7925t375dEyZM0JgxY7Rnz55qa91utzp06KC///3vSkhI0M0336yHHnpIixcvrnfD09LSVFJS4pmOHDlS720CAABz8mnQrSQFBgaqW7dukqSEhATt2LFDCxcu1JIlS6rUhoeHKyAgQP7+/p55sbGxKiwsVEVFhS644AL5+/vr2LFjXusdO3ZMYWFhtbbDarXKarX62nwAANAE1fs5LG63W+Xl5dUuGzRokA4cOCC32+2Zt3//foWHhyswMFCBgYFKSEjQe++957W99957r8ZxMQAA4NfHp8CSlpam999/X4cOHVJeXp7S0tK0ceNGjR49WpKUnJystLQ0T/2ECRN0/PhxTZkyRfv379fq1as1Z84cpaSkeGruu+8+Pfvss1q+fLm++OILTZgwQaWlpbrjjjsaqIsAAKCp8+mSUFFRkZKTk1VQUCC73a74+Hjl5uZq8ODBkqT8/Hz5+f0vA0VHRys3N1f33nuv4uPjFRkZqSlTpig1NdVTc/PNN+vbb7/VI488osLCQvXp00dvv/12lYG4AADg16vez2ExC57DAgBA09Poz2EBAAA4VwgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9HwKLJmZmYqPj5fNZpPNZpPD4dDatWtrrF+2bJksFovX1LJlS6+akydPatKkSYqKilJQUJB69uypxYsXn11vAABAs9TCl+KoqCjNnTtXMTExMgxDy5cvV1JSknbt2qW4uLhq17HZbNq3b5/ns8Vi8Vp+3333af369Xr55ZfVuXNnvfPOO5o4caIiIiI0YsSIs+gSAABobnw6wzJ8+HD9/ve/V0xMjLp3767Zs2crODhY27Ztq3Edi8WisLAwzxQaGuq1fMuWLRozZoyuvPJKde7cWePGjVPv3r310UcfnV2PAABAs3PWY1hcLpeysrJUWloqh8NRY93JkyfVqVMnRUdHKykpSZ9//rnX8oEDB2rVqlX65ptvZBiGNmzYoP379+uaa66pdf/l5eVyOp1eEwAAaJ58Dix5eXkKDg6W1WrV+PHjlZOTo549e1Zb26NHDz3//PP617/+pZdffllut1sDBw7U119/7al5+umn1bNnT0VFRSkwMFBDhw7VM888o8svv7zWdqSnp8tut3um6OhoX7sCAACaCIthGIYvK1RUVCg/P18lJSXKzs7Wc889p02bNtUYWn6usrJSsbGxGjVqlB599FFJ0rx58/Tss89q3rx56tSpk95//32lpaUpJydHiYmJNW6rvLxc5eXlns9Op1PR0dEqKSmRzWbzpUsAAOA8cTqdstvtZ/z99jmw/FJiYqK6du2qJUuW1Kn+xhtvVIsWLfTKK6/oxx9/lN1uV05Ojq699lpPzZ133qmvv/5ab7/9dp3bUdcOAwAA86jr73e9n8Pidru9znTUxuVyKS8vT+Hh4ZJOnXGprKyUn593M/z9/eV2u+vbNAAA0Ez4dFtzWlqahg0bpo4dO+rEiRNasWKFNm7cqNzcXElScnKyIiMjlZ6eLkmaNWuWfvvb36pbt24qLi5WRkaGDh8+rDvvvFPSqVuer7jiCk2dOlVBQUHq1KmTNm3apBdffFHz589v4K4CAICmyqfAUlRUpOTkZBUUFMhutys+Pl65ubkaPHiwJCk/P9/rbMn333+vu+66S4WFhWrbtq0SEhK0ZcsWr/EuWVlZSktL0+jRo3X8+HF16tRJs2fP1vjx4xuoiwAAoKmr9xgWs2AMCwAATc85G8MCAADQ2AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9AgsAADA9HwKLJmZmYqPj5fNZpPNZpPD4dDatWtrrF+2bJksFovX1LJlyyp1X3zxhUaMGCG73a7WrVurX79+ys/P9703AACgWWrhS3FUVJTmzp2rmJgYGYah5cuXKykpSbt27VJcXFy169hsNu3bt8/z2WKxeC3/z3/+o8suu0xjx47VzJkzZbPZ9Pnnn1cbbAAAwK+TxTAMoz4baNeunTIyMjR27Ngqy5YtW6Z77rlHxcXFNa5/yy23KCAgQC+99FJ9miGn0ym73a6SkhLZbLZ6bQsAAJwbdf39PusxLC6XS1lZWSotLZXD4aix7uTJk+rUqZOio6OVlJSkzz//3LPM7XZr9erV6t69u4YMGaIOHTpowIABeuONN862WQAAoBnyObDk5eUpODhYVqtV48ePV05Ojnr27FltbY8ePfT888/rX//6l15++WW53W4NHDhQX3/9tSSpqKhIJ0+e1Ny5czV06FC98847uv766/WHP/xBmzZtqrUd5eXlcjqdXhMAAGiefL4kVFFRofz8fJWUlCg7O1vPPfecNm3aVGNo+bnKykrFxsZq1KhRevTRR3X06FFFRkZq1KhRWrFihaduxIgRat26tV555ZUatzVjxgzNnDmzynwuCQEA0HQ02iWhwMBAdevWTQkJCUpPT1fv3r21cOHCOq0bEBCgSy+9VAcOHJAkXXDBBWrRokWVsBMbG3vGu4TS0tJUUlLimY4cOeJrVwAAQBNR7+ewuN1ulZeX16nW5XIpLy9P4eHhkk6Fn379+nndRSRJ+/fvV6dOnWrdltVq9dxefXoCAADNk0+3NaelpWnYsGHq2LGjTpw4oRUrVmjjxo3Kzc2VJCUnJysyMlLp6emSpFmzZum3v/2tunXrpuLiYmVkZOjw4cO68847PducOnWqbr75Zl1++eW66qqr9Pbbb+vNN9/Uxo0bG66XAACgSfMpsBQVFSk5OVkFBQWy2+2Kj49Xbm6uBg8eLEnKz8+Xn9//Ttp8//33uuuuu1RYWKi2bdsqISFBW7Zs8boEdP3112vx4sVKT0/X5MmT1aNHD7322mu67LLLGqiLAACgqav3c1jMguewAADQ9DT6c1gAAADOFQILAAAwPQILAAAwPQILAAAwPQILAAAwPZ9uazaz0zc78U4hAACajtO/22e6abnZBJYTJ05IkqKjo89zSwAAgK9OnDghu91e4/Jm8xwWt9uto0ePqk2bNrJYLOe7OeeV0+lUdHS0jhw5wjNpGhHH+dzhWJ8bHOdzg+PszTAMnThxQhEREV4Pn/2lZnOGxc/PT1FRUee7GabCO5bODY7zucOxPjc4zucGx/l/ajuzchqDbgEAgOkRWAAAgOkRWJohq9Wq6dOny2q1nu+mNGsc53OHY31ucJzPDY7z2Wk2g24BAEDzxRkWAABgegQWAABgegQWAABgegQWAABgegSWJur48eMaPXq0bDabQkJCNHbsWJ08ebLWdcrKypSSkqL27dsrODhYN9xwg44dO1Zt7XfffaeoqChZLBYVFxc3Qg+ahsY4zp9++qlGjRql6OhoBQUFKTY2VgsXLmzsrpjKM888o86dO6tly5YaMGCAPvroo1rrV65cqYsvvlgtW7ZUr169tGbNGq/lhmHokUceUXh4uIKCgpSYmKgvv/yyMbvQJDTkca6srFRqaqp69eql1q1bKyIiQsnJyTp69Ghjd6NJaOjv9M+NHz9eFotFCxYsaOBWNzEGmqShQ4cavXv3NrZt22Z88MEHRrdu3YxRo0bVus748eON6Oho47333jN27txp/Pa3vzUGDhxYbW1SUpIxbNgwQ5Lx/fffN0IPmobGOM5Lly41Jk+ebGzcuNH4z3/+Y7z00ktGUFCQ8fTTTzd2d0whKyvLCAwMNJ5//nnj888/N+666y4jJCTEOHbsWLX1mzdvNvz9/Y0nnnjC2LNnj/Hwww8bAQEBRl5enqdm7ty5ht1uN9544w3j008/NUaMGGF06dLF+PHHH89Vt0ynoY9zcXGxkZiYaLz66qvG3r17ja1btxr9+/c3EhISzmW3TKkxvtOnvf7660bv3r2NiIgI469//Wsj98TcCCxN0J49ewxJxo4dOzzz1q5da1gsFuObb76pdp3i4mIjICDAWLlypWfeF198YUgytm7d6lX7t7/9zbjiiiuM995771cdWBr7OP/cxIkTjauuuqrhGm9i/fv3N1JSUjyfXS6XERERYaSnp1dbf9NNNxnXXnut17wBAwYYf/7znw3DMAy3222EhYUZGRkZnuXFxcWG1Wo1XnnllUboQdPQ0Me5Oh999JEhyTh8+HDDNLqJaqxj/fXXXxuRkZHGZ599ZnTq1OlXH1i4JNQEbd26VSEhIerbt69nXmJiovz8/LR9+/Zq1/n4449VWVmpxMREz7yLL75YHTt21NatWz3z9uzZo1mzZunFF1+s9SVUvwaNeZx/qaSkRO3atWu4xptURUWFPv74Y6/j4+fnp8TExBqPz9atW73qJWnIkCGe+oMHD6qwsNCrxm63a8CAAbUe8+asMY5zdUpKSmSxWBQSEtIg7W6KGutYu91u3XbbbZo6dari4uIap/FNzK/7F6mJKiwsVIcOHbzmtWjRQu3atVNhYWGN6wQGBlb5D0toaKhnnfLyco0aNUoZGRnq2LFjo7S9KWms4/xLW7Zs0auvvqpx48Y1SLvN7L///a9cLpdCQ0O95td2fAoLC2utP/2nL9ts7hrjOP9SWVmZUlNTNWrUqF/1C/wa61g//vjjatGihSZPntzwjW6iCCwm8uCDD8pisdQ67d27t9H2n5aWptjYWN16662Ntg8zON/H+ec+++wzJSUlafr06brmmmvOyT6B+qqsrNRNN90kwzCUmZl5vpvT7Hz88cdauHChli1bJovFcr6bYxotzncD8D/333+/br/99lprLrroIoWFhamoqMhr/k8//aTjx48rLCys2vXCwsJUUVGh4uJir//7P3bsmGed9evXKy8vT9nZ2ZJO3XkhSRdccIEeeughzZw58yx7Zi7n+ziftmfPHl199dUaN26cHn744bPqS1NzwQUXyN/fv8rdadUdn9PCwsJqrT/957FjxxQeHu5V06dPnwZsfdPRGMf5tNNh5fDhw1q/fv2v+uyK1DjH+oMPPlBRUZHXmW6Xy6X7779fCxYs0KFDhxq2E03F+R5EA9+dHgy6c+dOz7zc3Nw6DQbNzs72zNu7d6/XYNADBw4YeXl5nun55583JBlbtmypcbR7c9ZYx9kwDOOzzz4zOnToYEydOrXxOmBS/fv3NyZNmuT57HK5jMjIyFoHKF533XVe8xwOR5VBt/PmzfMsLykpYdBtAx9nwzCMiooKY+TIkUZcXJxRVFTUOA1vghr6WP/3v//1+m9xXl6eERERYaSmphp79+5tvI6YHIGliRo6dKhx6aWXGtu3bzc+/PBDIyYmxut226+//tro0aOHsX37ds+88ePHGx07djTWr19v7Ny503A4HIbD4ahxHxs2bPhV3yVkGI1znPPy8owLL7zQuPXWW42CggLP9Gv5AcjKyjKsVquxbNkyY8+ePca4ceOMkJAQo7Cw0DAMw7jtttuMBx980FO/efNmo0WLFsa8efOML774wpg+fXq1tzWHhIQY//rXv4x///vfRlJSErc1N/BxrqioMEaMGGFERUUZu3fv9vrulpeXn5c+mkVjfKd/ibuECCxN1nfffWeMGjXKCA4ONmw2m3HHHXcYJ06c8Cw/ePCgIcnYsGGDZ96PP/5oTJw40Wjbtq3RqlUr4/rrrzcKCgpq3AeBpXGO8/Tp0w1JVaZOnTqdw56dX08//bTRsWNHIzAw0Ojfv7+xbds2z7IrrrjCGDNmjFf9P//5T6N79+5GYGCgERcXZ6xevdprudvtNqZNm2aEhoYaVqvVuPrqq419+/adi66YWkMe59Pf9eqmn3//f60a+jv9SwQWw7AYxv8bqAAAAGBS3CUEAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABMj8ACAABM7/8HcK4ozyR71fQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the losses and save them\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(validation_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.savefig('models/losses.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jskaf/Documents/Cours ECM 3A/CV/Clothes-similarity/clothes_sim/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of     0 :  0 %\n",
      "No test data for class 1\n",
      "Accuracy of     2 :  0 %\n",
      "Accuracy of     3 :  0 %\n",
      "Accuracy of     4 :  0 %\n",
      "Accuracy of     5 :  0 %\n",
      "Accuracy of     6 :  0 %\n",
      "Accuracy of     7 :  0 %\n",
      "Accuracy of     8 :  0 %\n",
      "Accuracy of     9 :  0 %\n",
      "No test data for class 10\n",
      "No test data for class 11\n",
      "No test data for class 12\n",
      "Accuracy of    13 :  0 %\n",
      "Accuracy of    14 :  0 %\n",
      "Accuracy of    15 :  0 %\n",
      "Accuracy of    16 :  0 %\n",
      "Accuracy of    17 :  0 %\n",
      "No test data for class 18\n",
      "Accuracy of    19 :  0 %\n",
      "Accuracy of    20 :  0 %\n",
      "Accuracy of    21 :  0 %\n",
      "No test data for class 22\n",
      "Accuracy of    23 :  0 %\n",
      "No test data for class 24\n",
      "Accuracy of    25 :  0 %\n",
      "Accuracy of    26 :  0 %\n",
      "Accuracy of    27 :  0 %\n",
      "Accuracy of    28 :  0 %\n",
      "Accuracy of    29 :  0 %\n",
      "Accuracy of    30 :  0 %\n",
      "Accuracy of    31 :  0 %\n",
      "Accuracy of    32 :  0 %\n",
      "Accuracy of    33 :  0 %\n",
      "Accuracy of    34 :  0 %\n",
      "No test data for class 35\n",
      "Accuracy of    36 :  0 %\n",
      "No test data for class 37\n",
      "No test data for class 38\n",
      "Accuracy of    39 :  0 %\n",
      "Accuracy of    40 :  0 %\n",
      "No test data for class 41\n",
      "No test data for class 42\n",
      "No test data for class 43\n",
      "No test data for class 44\n",
      "No test data for class 45\n",
      "Accuracy of    46 :  0 %\n",
      "Accuracy of    47 : 13 %\n",
      "Accuracy of    48 :  0 %\n",
      "Accuracy of    49 :  0 %\n",
      "Accuracy of    50 :  0 %\n",
      "Accuracy of    51 :  0 %\n",
      "Accuracy of    52 :  0 %\n",
      "Accuracy of    53 :  0 %\n",
      "Accuracy of    54 :  0 %\n",
      "No test data for class 55\n",
      "No test data for class 56\n",
      "Accuracy of    57 :  0 %\n",
      "Accuracy of    58 :  0 %\n",
      "Accuracy of    59 :  0 %\n",
      "Accuracy of    60 : 36 %\n",
      "Accuracy of    61 :  0 %\n",
      "Accuracy of    62 :  0 %\n",
      "Accuracy of    63 :  0 %\n",
      "No test data for class 64\n",
      "Accuracy of    65 : 51 %\n",
      "Accuracy of    66 :  0 %\n",
      "Accuracy of    67 :  0 %\n",
      "Accuracy of    68 :  0 %\n",
      "Accuracy of    69 :  0 %\n",
      "No test data for class 70\n",
      "Accuracy of    71 :  0 %\n",
      "No test data for class 72\n",
      "No test data for class 73\n",
      "Accuracy of    74 :  0 %\n",
      "No test data for class 75\n",
      "Accuracy of    76 :  0 %\n",
      "No test data for class 77\n",
      "No test data for class 78\n",
      "Accuracy of    79 :  0 %\n",
      "Accuracy of    80 :  0 %\n",
      "Accuracy of    81 :  0 %\n",
      "Accuracy of    82 :  0 %\n",
      "Accuracy of    83 :  0 %\n",
      "Accuracy of    84 :  0 %\n",
      "No test data for class 85\n",
      "Accuracy of    86 :  0 %\n",
      "No test data for class 87\n",
      "Accuracy of    88 :  0 %\n",
      "Accuracy of    89 :  0 %\n",
      "Accuracy of    90 :  0 %\n",
      "No test data for class 91\n",
      "Accuracy of    92 :  0 %\n",
      "Accuracy of    93 :  0 %\n",
      "No test data for class 94\n",
      "No test data for class 95\n",
      "No test data for class 96\n",
      "No test data for class 97\n",
      "No test data for class 98\n",
      "No test data for class 99\n",
      "Accuracy of   100 :  0 %\n",
      "No test data for class 101\n",
      "No test data for class 102\n",
      "No test data for class 103\n",
      "No test data for class 104\n",
      "No test data for class 105\n",
      "No test data for class 106\n",
      "No test data for class 107\n",
      "No test data for class 108\n",
      "No test data for class 109\n",
      "No test data for class 110\n",
      "No test data for class 111\n",
      "No test data for class 112\n",
      "Accuracy of   113 :  0 %\n",
      "No test data for class 114\n",
      "No test data for class 115\n",
      "No test data for class 116\n",
      "No test data for class 117\n",
      "No test data for class 118\n",
      "No test data for class 119\n",
      "No test data for class 120\n",
      "No test data for class 121\n",
      "Accuracy of   122 :  0 %\n",
      "No test data for class 123\n",
      "No test data for class 124\n",
      "No test data for class 125\n",
      "No test data for class 126\n",
      "No test data for class 127\n",
      "No test data for class 128\n",
      "No test data for class 129\n",
      "No test data for class 130\n",
      "No test data for class 131\n"
     ]
    }
   ],
   "source": [
    "#Test the model for each class\n",
    "def test(model, test_loader):\n",
    "    global num_classes\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        index_batch = 0\n",
    "        class_correct = list(0. for i in range(num_classes))\n",
    "        class_total = list(0. for i in range(num_classes))\n",
    "        for batch in test_loader:\n",
    "            images, labels, _ , _ = batch\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "            index_batch += 1\n",
    "            print('Batch {} out of {}'.format(index_batch, len(train_loader)), end='\\r')\n",
    "            # if index_batch%10 == 0:\n",
    "            #     print('Batch {} out of {}'.format(index_batch, len(test_loader)))\n",
    "\n",
    "        for i in range(num_classes):\n",
    "            if class_total[i] == 0:\n",
    "                print('No test data for class {}'.format(i))\n",
    "            else:\n",
    "                print('Accuracy of %5s : %2d %%' % (i, 100 * class_correct[i] / class_total[i]))\n",
    "            \n",
    "test(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
