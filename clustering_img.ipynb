{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from dataset import myDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    }
   ],
   "source": [
    "# Define device variable for cuda, mps or cpu\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Using CUDA')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('Using MPS')\n",
    "else :\n",
    "    device = torch.device('cpu')\n",
    "    print('Using CPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want to use a resnet50 from torchvision to have the embedding of an image, use a pretrained resnet and remove the last layer\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.resnet = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained=True)\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        self.resnet.eval()\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusteringModel(nn.Module):\n",
    "    def __init__(self, num_embeddings, num_clusters):\n",
    "        super(ClusteringModel, self).__init__()\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.num_clusters = num_clusters\n",
    "        self.centers = nn.Parameter(torch.randn(num_clusters, num_embeddings))\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        embeddings = embeddings.flatten(2).flatten(1)\n",
    "        # Compute the distance between each embedding and each cluster center\n",
    "        distances = torch.cdist(embeddings, self.centers)\n",
    "        # Assign each embedding to the closest cluster\n",
    "        assignments = torch.argmin(distances, dim=1)\n",
    "        return assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_loss(model, embeddings):\n",
    "    assignments = model(embeddings)\n",
    "    # Compute the loss as the sum of the distances between each embedding and its assigned cluster center\n",
    "    embeddings = embeddings.flatten(2).flatten(1)\n",
    "    distances = torch.cdist(embeddings, model.centers)\n",
    "    loss = torch.sum(torch.gather(distances, 1, assignments.unsqueeze(1)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/jskaf/.cache/torch/hub/pytorch_vision_v0.6.0\n",
      "/Users/jskaf/miniconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/jskaf/miniconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet_model = ResNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the dataset\n",
    "\n",
    "get_preprocessed_image = True\n",
    "train_test_split = 0.9\n",
    "my_path_hm = os.path.join(os.getcwd(), 'data/h&mdataset/images/')\n",
    "my_path_fash = os.path.join(os.getcwd(), 'data/fashion-dataset/images/')\n",
    "\n",
    "dataset = myDataset(my_path_hm, my_path_fash, get_preprocessed_image, 'hm')\n",
    "\n",
    "#Split the dataset into training and testing\n",
    "train_size = int(train_test_split * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=10, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choice of cluster number : we have 143 article type 20 color, so a number between 100 et 300 can be a good choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1478/1478 [08:35<00:00,  2.87it/s]\n",
      "  5%|▌         | 74/1478 [00:36<07:40,  3.05it/s] "
     ]
    }
   ],
   "source": [
    "embeddings_size = 2048\n",
    "\n",
    "# Initialize a list to hold the loss for each number of clusters\n",
    "losses = []\n",
    "\n",
    "# Loop over different numbers of clusters\n",
    "for num_clusters in range(100, 300, 30):  # Adjust the range as needed\n",
    "    # Initialize the clustering model\n",
    "    clustering_model = ClusteringModel(embeddings_size, num_clusters).to(device)  # Assuming that 'model.embedding_size' is the size of your embeddings\n",
    "\n",
    "    # Initialize the optimizer\n",
    "    optimizer = optim.Adam(clustering_model.parameters(), lr=0.001)  # Adjust the learning rate as needed\n",
    "\n",
    "    # Train the clustering model\n",
    "    num_epochs = 10  # Adjust as needed\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in tqdm(train_loader):\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            embeddings = resnet_model(batch)  # Compute the embeddings for the current batch of images\n",
    "            loss = clustering_loss(clustering_model, embeddings)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the elbow graph\n",
    "plt.plot(range(2, 11), losses, 'bx-')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Elbow Method For Optimal Number of Clusters')\n",
    "plt.show()\n",
    "\n",
    "#save the plot\n",
    "plt.savefig('elbow_plot_img.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
