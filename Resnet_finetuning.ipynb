{"cells":[{"cell_type":"markdown","metadata":{"id":"Kv4sGeDyHBWV"},"source":["# Clothes Similarity, inspired from TP1 CV finetuning"]},{"cell_type":"markdown","metadata":{},"source":["## Step 1 : finetuning Resnet50 for classification"]},{"cell_type":"markdown","metadata":{"id":"8dohW_X2KqWU"},"source":["### Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"XBaSRtigHBok"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From C:\\Users\\emend\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n","\n"]}],"source":["import os\n","import yaml\n","import subprocess\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import platform\n","import shutil\n","import cv2\n","from IPython.display import clear_output\n","from sklearn.model_selection import train_test_split\n","from tqdm.notebook import tqdm\n","from sklearn.manifold import TSNE\n","from dataset_emma import myDataset\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, BatchNormalization\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","from keras.preprocessing import image\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"]},{"cell_type":"markdown","metadata":{},"source":["### Récupération des données"]},{"cell_type":"markdown","metadata":{},"source":["Paths"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["data_dir, images_dir :  C:\\Users\\emend\\3A_new\\3A_new\\Computer_Vision\\h-and-m-personalized-fashion-recommendations C:\\Users\\emend\\3A_new\\3A_new\\Computer_Vision\\h-and-m-personalized-fashion-recommendations\\images\n","output_dir :  C:\\Users\\emend\\3A_new\\3A_new\\Computer_Vision\\h-and-m-personalized-fashion-recommendations\\output\n"]}],"source":["# Charger les configurations depuis le fichier YAML\n","with open(\"./config.yaml\", 'r') as file:\n","    try:    \n","        config = yaml.safe_load(file)\n","    except yaml.YAMLError as exc:\n","        print(exc)\n","\n","# Chemin vers le répertoire de données\n","data_dir = config[\"paths\"][\"data_path\"]\n","\n","# Chemin vers le répertoire des images\n","images_dir = os.path.join(data_dir, \"images\")\n","print('data_dir, images_dir : ', data_dir, images_dir)\n","\n","# Chemin vers le répertoire de sortie\n","output_dir = os.path.join(data_dir, 'output')\n","print(\"output_dir : \", output_dir)\n","\n","# Vérification et création du répertoire de sortie\n","if not os.path.exists(output_dir):\n","     os.makedirs(output_dir)"]},{"cell_type":"markdown","metadata":{},"source":["Création d'un dossier unique contenant les images format 224*224"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Parcours des sous-répertoires dans le répertoire des images pour créer nouveau répertoire de sortie\n","\n","# # Liste des sous-répertoires dans le répertoire des images\n","# dirs_ = os.listdir(images_dir)\n","\n","# Nombre total d'images à traiter\n","# n = len(os.listdir(images_dir))\n","\n","# for idx, dir in enumerate(dirs_):\n","#     print(f\"Dossier {idx}/{n}\")\n","    \n","#     # Parcours des images dans chaque sous-répertoire\n","#     for image in tqdm(os.listdir(os.path.join(images_dir, dir))):\n","#         # Chemin complet de l'image source\n","#         source_path = os.path.join(images_dir, dir, image)\n","#         # Chemin complet de l'image destination\n","#         destination_path = os.path.join(output_dir, image)\n","\n","#         # Normaliser le chemin source\n","#         source_path = os.path.normpath(source_path)\n","#         # Normaliser le chemin destination\n","#         destination_path = os.path.normpath(destination_path)\n","\n","#         # Déterminer le système d'exploitation\n","#         system = platform.system()\n","#         # Choix de la commande de copie en fonction du système d'exploitation\n","#         if system == \"Windows\":\n","#             copy_command = \"copy\"\n","#         else:\n","#             copy_command = \"cp\"\n","        \n","#         # Copie du fichier\n","#         shutil.copy(source_path, destination_path)"]},{"cell_type":"markdown","metadata":{"id":"t06SWtvbJQMi"},"source":["Chargement des données\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"NBgvPV9WFRh1"},"outputs":[],"source":["dataset = myDataset(output_dir, get_preprocessed_image = False)\n","img_path = output_dir"]},{"cell_type":"markdown","metadata":{},"source":["Création d'un sous-dossier (facultatif)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["img_path = os.path.join(data_dir, 'smaller_dataset')\n","# dataset.create_smaller_dataset(data_dir, 'smaller_dataset', 2000)"]},{"cell_type":"markdown","metadata":{},"source":["### Préparation X et y"]},{"cell_type":"markdown","metadata":{},"source":["X"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Données X\n","X_names = os.listdir(img_path)\n","\n","# Liste pour stocker les images\n","images = []\n","\n","# Parcourir chaque nom de fichier dans X_names et lire l'image correspondante\n","for filename in X_names:\n","    full_path = os.path.join(img_path, filename)\n","    # target_size = (224, 224)\n","    image = cv2.imread(full_path)\n","    # if image is not None:\n","    #     image = cv2.resize(image, target_size)\n","    # else:\n","    #     print(\"Impossible de lire l'image.\")\n","    images.append(image)\n","\n","# Convertir la liste d'images en un tableau numpy\n","X = np.array(images)"]},{"cell_type":"markdown","metadata":{},"source":["y"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Données y\n","tabular_dir = config[\"paths\"][\"tabular_path\"]\n","label_column = 'product_group_name'\n","\n","# Charger les labels de classes à partir du CSV\n","labels_df = pd.read_csv(tabular_dir)[['article_id', label_column]]\n","class_labels = labels_df[label_column].values \n","labels_df['article_id'] = labels_df['article_id'].astype(str)\n","keys_complete = X_names\n","keys = [int(image_name[1:-4]) for image_name in keys_complete]\n","\n","y = []\n","for idx in keys:\n","    idx = str(idx)\n","    if idx in labels_df['article_id'].values:\n","        y.append(labels_df[labels_df['article_id']==idx][label_column].values[0])\n","y = np.array(y)\n","\n","# Instancier l'encodeur\n","label_encoder = LabelEncoder()\n","\n","# Adapter l'encodeur aux étiquettes d'entraînement\n","y = label_encoder.fit_transform(y)"]},{"cell_type":"markdown","metadata":{},"source":["Split train/val/test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Divisez d'abord les données en ensembles d'entraînement et de test (par exemple 80% train, 20% test)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Ensuite, divisez l'ensemble de test en ensembles de test et de validation (par exemple 50% test, 50% validation)\n","X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"]},{"cell_type":"markdown","metadata":{},"source":["### Modele"]},{"cell_type":"markdown","metadata":{},"source":["Modèle ResNet50 + finetuning dernières couches"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Charger le modèle ResNet50 pré-entraîné sans la couche de classification (top)\n","base_model = ResNet50(weights='imagenet', include_top=False)\n","base_model_output = base_model.layers[-2].output\n","\n","\n","# Créer vos propres couches de classification\n","model_top = Sequential([\n","    GlobalAveragePooling2D(input_shape=base_model.output_shape[1:]),  # Global Average Pooling\n","    Dense(128, activation='relu'),  # Couche cachée\n","    Dense(len(np.unique(y)), activation='softmax')  # Couche de sortie avec softmax pour la classification\n","])\n","\n","# Combiner le modèle ResNet50 avec vos couches de classification\n","model = Model(inputs=base_model.input, outputs=model_top(base_model_output))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Geler les couches du modèle ResNet50 pré-entraîné\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# Compiler le modèle\n","optimizer = Adam(learning_rate=0.001)\n","model.compile(optimizer=optimizer,\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# # Définir les taux d'apprentissage pour les couches ResNet50 et Dense, respectivement\n","# lr_base = 0.001  \n","# lr_dense = 0.01  \n","\n","# # Créer un optimiseur avec différents taux d'apprentissage pour chaque couche\n","# optimizer = Adam(learning_rate=lr_base)\n","# for layer in model.layers:\n","#     if layer.name.startswith('resnet'):\n","#         optimizer.lr.assign(lr_base)\n","#     else:\n","#         optimizer.lr.assign(lr_dense)\n","\n","# # Compiler le modèle\n","# model.compile(optimizer=optimizer,\n","#               loss='sparse_categorical_crossentropy',\n","#               metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{},"source":["Train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","tf.config.run_functions_eagerly(True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Entraîner le modèle avec mini-batchs\n","batch_size = 32\n","epochs = 10\n","history = model.fit(X_train, y_train, \n","                    batch_size=batch_size, \n","                    epochs=epochs, \n","                    validation_data=(X_val, y_val))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# model.save(\"resnet_finetuned.h5\")"]},{"cell_type":"markdown","metadata":{},"source":["Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Évaluation du modèle sur l'ensemble de test\n","test_loss, test_acc = model.evaluate(X_test, y_test)\n","print('Test accuracy:', test_acc)"]},{"cell_type":"markdown","metadata":{},"source":["Scores"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = model.predict(X_test)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","\n","conf_matrix = confusion_matrix(y_test, y_pred_classes)\n","accuracy = accuracy_score(y_test, y_pred_classes)\n","precision = precision_score(y_test, y_pred_classes, average='weighted')\n","recall = recall_score(y_test, y_pred_classes, average='weighted')\n","f1 = f1_score(y_test, y_pred_classes, average='weighted')\n","\n","print('Matrice de confusion :\\n', conf_matrix)\n","print('Accuracy :', accuracy)\n","print('Précision :', precision)\n","print('Rappel :', recall)\n","print('F1-score :', f1)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
